{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce376b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from suitability.filter.suitability_filter import get_sf_features, SuitabilityFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aec1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10  # MNIST has 10 classes (digits 0-9)\n",
    "IMG_SIZE = 28     # MNIST image size\n",
    "BATCH_SIZE = 64   # Adjusted batch size\n",
    "\n",
    "### DATA PREPARATION\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # Mean and std for MNIST\n",
    "])\n",
    "\n",
    "mnist_train_full = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test_full = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create subsets for our three data groups for the suitability filter\n",
    "# classifier_loader_sf: Data to train the prediction correctness classifier\n",
    "classifier_indices_sf = list(range(0, 1000))\n",
    "classifier_dataset_sf = Subset(mnist_train_full, classifier_indices_sf)\n",
    "classifier_loader_sf = DataLoader(classifier_dataset_sf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_indices_sf = list(range(0, 500))\n",
    "test_dataset_sf = Subset(mnist_test_full, test_indices_sf)\n",
    "test_loader_sf = DataLoader(test_dataset_sf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "user_indices_sf = list(range(500, 1000)) # Distinct from test_dataset_sf\n",
    "user_dataset_sf = Subset(mnist_test_full, user_indices_sf)\n",
    "user_loader_sf = DataLoader(user_dataset_sf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Classifier SF data: {len(classifier_dataset_sf)} samples from MNIST train\")\n",
    "print(f\"Test SF data: {len(test_dataset_sf)} samples from MNIST test\")\n",
    "print(f\"User SF data: {len(user_dataset_sf)} samples from MNIST test\")\n",
    "\n",
    "\n",
    "### MODEL DEFINITION\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) # MNIST is 1 channel\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 14x14 -> 7x7\n",
    "        self.fc = nn.Linear(32 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 7 * 7) # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "### FEATURE EXTRACTION\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "classifier_feats, classifier_corr = get_sf_features(classifier_loader_sf, model, device)\n",
    "print(f\"Shape of classifier_features: {classifier_feats.shape}\")\n",
    "print(f\"SF data correctness: {np.sum(classifier_corr)} correct out of {len(classifier_corr)} (approx accuracy: {np.mean(classifier_corr):.2f})\")\n",
    "\n",
    "test_feats, test_corr = get_sf_features(test_loader_sf, model, device)\n",
    "print(f\"Shape of test_features: {test_feats.shape}\")\n",
    "print(f\"Test correctness: {np.sum(test_corr)} correct out of {len(test_corr)} (approx accuracy: {np.mean(test_corr):.2f})\")\n",
    "\n",
    "user_feats, _ = get_sf_features(user_loader_sf, model, device)\n",
    "print(f\"Shape of user_features: {user_feats.shape}\")\n",
    "\n",
    "### SUITABILITY FILTER\n",
    "\n",
    "sf_filter = SuitabilityFilter(\n",
    "    test_features=test_feats,\n",
    "    test_corr=test_corr, # Correctness of primary model on SF's \"test\" data\n",
    "    classifier_features=classifier_feats,\n",
    "    classifier_corr=classifier_corr, # Correctness of primary model on SF's \"classifier training\" data\n",
    "    device=device,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "sf_filter.train_classifier(classifier_name=\"logistic_regression\", calibrated=True)\n",
    "test_margin = 0.01 \n",
    "\n",
    "results = sf_filter.suitability_test(user_features=user_feats, margin=test_margin)\n",
    "print(\"\\nSuitability Test Results:\")\n",
    "for key, value in results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if results['p_value'] < alpha:\n",
    "    print(f\"\\nUser data IS considered non-inferior (p={results['p_value']:.4f} < {alpha}). The new data is not significantly worse than the test data by more than the margin.\")\n",
    "else:\n",
    "    print(f\"\\nUser data is NOT proven non-inferior (p={results['p_value']:.4f} >= {alpha}). We cannot conclude that the new data is within the non-inferiority margin of the test data.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
