{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the suitability filter on RxRx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter import suitability_efficient\n",
    "\n",
    "importlib.reload(suitability_efficient)\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter, get_sf_features\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & evaluate all possible splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_splits = [\n",
    "    (\"val\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"val\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"val\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"val\", {\"cell_type\": \"U2OS\"}),\n",
    "    (\"val\", {})\n",
    "]\n",
    "\n",
    "id_test_splits = [\n",
    "    (\"id_test\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"U2OS\"}),\n",
    "    (\"id_test\", {})\n",
    "]\n",
    "\n",
    "test_splits = [\n",
    "    (\"test\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"test\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"test\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"test\", {\"cell_type\": \"U2OS\"}),\n",
    "    (\"test\", {})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_3048830/3639878652.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = results._append(\n"
     ]
    }
   ],
   "source": [
    "data_name = \"rxrx1\"\n",
    "root_dir = \"/mfsnic/u/apouget/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_wilds_model(data_name, root_dir, algorithm=\"ERM\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_splits = val_splits + test_splits + id_test_splits\n",
    "\n",
    "results = pd.DataFrame(columns=[\"split\", \"cell_type\", \"num_samples\", \"accuracy\"])\n",
    "\n",
    "for split, pre_filter in all_splits:\n",
    "    data = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=pre_filter,\n",
    "    )\n",
    "    features, corr = get_sf_features(data, model, device)\n",
    "\n",
    "    num_samples = len(data.dataset)\n",
    "    accuracy = np.mean(corr)\n",
    "    cell_type = pre_filter.get(\"cell_type\", \"ALL\")\n",
    "    results = results._append(\n",
    "        {\n",
    "            \"split\": split,\n",
    "            \"cell_type\": cell_type,\n",
    "            \"num_samples\": num_samples,\n",
    "            \"accuracy\": accuracy,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "results.to_csv(\"suitability/results/data_splits/rxrx1_ERM_0_last.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate suitability filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to device: cuda\n",
      "Computing features for split: val\n",
      "Computing features for split: test\n",
      "Computing features for split: id_test\n",
      "Features computed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter, get_sf_features\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"rxrx1\"\n",
    "root_dir = \"/mfsnic/u/apouget/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"groupDRO\"\n",
    "model_type = \"last\"\n",
    "seed = 0\n",
    "model = get_wilds_model(\n",
    "    data_name, root_dir, algorithm=algorithm, seed=seed, model_type=model_type\n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded to device: {device}\")\n",
    "\n",
    "# Initialize results DataFrame\n",
    "features_cache_file = (\n",
    "    f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    ")\n",
    "valid_splits = [\"val\", \"test\", \"id_test\"]\n",
    "splits_features_cache = {}\n",
    "\n",
    "# Precompute all data features\n",
    "for split_name in valid_splits:\n",
    "    print(f\"Computing features for split: {split_name}\")\n",
    "    dataset = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    splits_features_cache[split_name] = get_sf_features(dataset, model, device)\n",
    "print(\"Features computed\")\n",
    "\n",
    "# Save feature cache\n",
    "with open(features_cache_file, \"wb\") as f:\n",
    "    pickle.dump(splits_features_cache, f)\n",
    "\n",
    "# Precompute all id split indices\n",
    "cache_file = f\"suitability/results/split_indices/{data_name}.pkl\"\n",
    "\n",
    "valid_splits = [\n",
    "    (\"val\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"val\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"val\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"val\", {\"cell_type\": \"U2OS\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"id_test\", {\"cell_type\": \"U2OS\"}),\n",
    "    (\"test\", {\"cell_type\": \"HEPG2\"}),\n",
    "    (\"test\", {\"cell_type\": \"HUVEC\"}),\n",
    "    (\"test\", {\"cell_type\": \"RPE\"}),\n",
    "    (\"test\", {\"cell_type\": \"U2OS\"}),\n",
    "]\n",
    "\n",
    "splits_indices_cache = {}\n",
    "for split_name, split_filter in valid_splits:\n",
    "    print(f\"Computing indices for split: {split_name} with filter: {split_filter}\")\n",
    "    dataset, indices = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=split_filter,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    splits_indices_cache[(split_name, str(split_filter))] = indices\n",
    "\n",
    "with open(cache_file, \"wb\") as f:\n",
    "    pickle.dump(splits_indices_cache, f)\n",
    "\n",
    "print(\"splits indices computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD SPLIT SUBSET EVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'cell_type': 'HEPG2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▍                                                                                                    | 1/8 [01:49<12:44, 109.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'cell_type': 'HUVEC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████▊                                                                                      | 2/8 [03:37<10:53, 108.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'cell_type': 'RPE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████▏                                                                       | 3/8 [05:25<09:01, 108.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'cell_type': 'U2OS'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████▌                                                         | 4/8 [07:11<07:10, 107.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'cell_type': 'HEPG2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████▉                                           | 5/8 [09:03<05:27, 109.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'cell_type': 'HUVEC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 6/8 [11:04<03:46, 113.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'cell_type': 'RPE'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter\n",
    "from suitability.filter.tests import non_inferiority_ttest\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"rxrx1\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"ERM\"\n",
    "model_type = \"last\"\n",
    "seed = 2\n",
    "\n",
    "# Load the features\n",
    "feature_cache_file = (\n",
    "    f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    ")\n",
    "with open(feature_cache_file, \"rb\") as f:\n",
    "    full_feature_dict = pickle.load(f)\n",
    "\n",
    "# Load the split indices\n",
    "split_cache_file = f\"suitability/results/split_indices/{data_name}.pkl\"\n",
    "with open(split_cache_file, \"rb\") as f:\n",
    "    ood_split_dict = pickle.load(f)\n",
    "\n",
    "all_keys = list(ood_split_dict.keys())\n",
    "for key in all_keys:\n",
    "    if key[0] == 'id_test':\n",
    "        del ood_split_dict[key]\n",
    "\n",
    "# Define suitability filter and experiment parameters\n",
    "classifiers = [\n",
    "    \"logistic_regression\"\n",
    "]  # \"logistic_regression\", \"svm\", \"random_forest\", \"gradient_boosting\", \"mlp\", \"decision_tree\"]\n",
    "margins = [0, 0.005, 0.01, 0.05]\n",
    "normalize = True\n",
    "calibrated = True\n",
    "sf_results = []\n",
    "direct_testing_results = []\n",
    "feature_subsets = [\n",
    "    [0],\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4],\n",
    "    [5],\n",
    "    [6],\n",
    "    [7],\n",
    "    [8],\n",
    "    [9],\n",
    "    [10],\n",
    "    [11],\n",
    "    # [4, 11],\n",
    "    # [4, 11, 8],\n",
    "    # [4, 11, 8, 6],\n",
    "    # [4, 11, 8, 6, 2],\n",
    "    # [4, 11, 8, 6, 2, 1],\n",
    "    # [4, 11, 8, 6, 2, 1, 0],\n",
    "    # [4, 11, 8, 6, 2, 1, 0, 7],\n",
    "    # [4, 11, 8, 6, 2, 1, 0, 7, 3],\n",
    "    # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10],\n",
    "    # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10, 5],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "]\n",
    "num_fold_arr = [15]\n",
    "\n",
    "source_features, source_corr = full_feature_dict[\"id_test\"]\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for user_split_name, user_filter in tqdm(ood_split_dict.keys()):\n",
    "    print(f\"Evaluating user split: {user_split_name} with filter {user_filter}\")\n",
    "\n",
    "    # Get user split indices\n",
    "    user_split_indices = ood_split_dict[(user_split_name, user_filter)]\n",
    "\n",
    "    # Get user split features and correctness\n",
    "    all_features, all_corr = full_feature_dict[user_split_name]\n",
    "    user_features = all_features[user_split_indices]\n",
    "    user_corr = all_corr[user_split_indices]\n",
    "    user_size = len(user_corr)\n",
    "    user_acc = np.mean(user_corr)\n",
    "\n",
    "    for num_folds in num_fold_arr:\n",
    "        source_fold_size = len(source_corr) // num_folds\n",
    "        indices = np.arange(len(source_corr))\n",
    "        np.random.shuffle(indices)\n",
    "        fold_indices = [\n",
    "            indices[i * source_fold_size : (i + 1) * source_fold_size]\n",
    "            for i in range(num_folds)\n",
    "        ]\n",
    "\n",
    "        for i, reg_indices in enumerate(fold_indices):\n",
    "            reg_features = source_features[reg_indices]\n",
    "            reg_corr = source_corr[reg_indices]\n",
    "            reg_size = len(reg_corr)\n",
    "            reg_acc = np.mean(reg_corr)\n",
    "\n",
    "            for j, test_indices in enumerate(fold_indices):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                test_features = source_features[test_indices]\n",
    "                test_corr = source_corr[test_indices]\n",
    "                test_size = len(test_corr)\n",
    "                test_acc = np.mean(test_corr)\n",
    "\n",
    "                for classifier in classifiers:\n",
    "                    for feature_subset in feature_subsets:\n",
    "                        suitability_filter = SuitabilityFilter(\n",
    "                            test_features,\n",
    "                            test_corr,\n",
    "                            reg_features,\n",
    "                            reg_corr,\n",
    "                            device,\n",
    "                            normalize=normalize,\n",
    "                            feature_subset=feature_subset,\n",
    "                        )\n",
    "                        suitability_filter.train_classifier(\n",
    "                            calibrated=calibrated, classifier=classifier\n",
    "                        )\n",
    "\n",
    "                        for margin in margins:\n",
    "                            # Test suitability filter\n",
    "                            sf_test = suitability_filter.suitability_test(\n",
    "                                user_features=user_features, margin=margin\n",
    "                            )\n",
    "                            p_value = sf_test[\"p_value\"]\n",
    "                            ground_truth = user_acc >= test_acc - margin\n",
    "\n",
    "                            sf_results.append(\n",
    "                                {\n",
    "                                    \"data_name\": data_name,\n",
    "                                    \"algorithm\": algorithm,\n",
    "                                    \"seed\": seed,\n",
    "                                    \"model_type\": model_type,\n",
    "                                    \"normalize\": normalize,\n",
    "                                    \"calibrated\": calibrated,\n",
    "                                    \"margin\": margin,\n",
    "                                    \"reg_fold\": i,\n",
    "                                    \"reg_size\": reg_size,\n",
    "                                    \"reg_acc\": reg_acc,\n",
    "                                    \"test_fold\": j,\n",
    "                                    \"test_size\": test_size,\n",
    "                                    \"test_acc\": test_acc,\n",
    "                                    \"user_split\": user_split_name,\n",
    "                                    \"user_filter\": user_filter,\n",
    "                                    \"user_size\": user_size,\n",
    "                                    \"user_acc\": user_acc,\n",
    "                                    \"p_value\": p_value,\n",
    "                                    \"ground_truth\": ground_truth,\n",
    "                                    \"classifier\": classifier,\n",
    "                                    \"feature_subset\": feature_subset,\n",
    "                                    \"acc_diff\": user_acc - test_acc,\n",
    "                                    \"acc_diff_adjusted\": user_acc + margin - test_acc,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "                            # Run non-inferiority test on features directly\n",
    "                            if (\n",
    "                                len(feature_subset) == 1\n",
    "                                and margin == 0\n",
    "                                and classifier == \"logistic_regression\"\n",
    "                                and (j == 0 or (i == 0 and j == 1))\n",
    "                            ):\n",
    "                                test_feature_subset = test_features[:, feature_subset].flatten()\n",
    "                                user_feature_subset = user_features[:, feature_subset].flatten()\n",
    "                                test_1 = non_inferiority_ttest(\n",
    "                                    test_feature_subset,\n",
    "                                    user_feature_subset,\n",
    "                                    increase_good=True,\n",
    "                                )\n",
    "                                test_2 = non_inferiority_ttest(\n",
    "                                    test_feature_subset,\n",
    "                                    user_feature_subset,\n",
    "                                    increase_good=False,\n",
    "                                )\n",
    "                                direct_testing_results.append(\n",
    "                                    {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"seed\": seed,\n",
    "                                        \"model_type\": model_type,\n",
    "                                        \"test_fold\": j,\n",
    "                                        \"test_size\": test_size,\n",
    "                                        \"test_acc\": test_acc,\n",
    "                                        \"user_split\": user_split_name,\n",
    "                                        \"user_filter\": user_filter,\n",
    "                                        \"user_size\": user_size,\n",
    "                                        \"user_acc\": user_acc,\n",
    "                                        \"p_value_increase_good\": test_1[\"p_value\"],\n",
    "                                        \"p_value_decrease_good\": test_2[\"p_value\"],\n",
    "                                        \"ground_truth\": ground_truth,\n",
    "                                        \"feature_subset\": feature_subset,\n",
    "                                        \"acc_diff\": user_acc - test_acc,\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "# Save results\n",
    "sf_evals = pd.DataFrame(sf_results)\n",
    "sf_evals.to_csv(\n",
    "    f\"suitability/results/sf_evals/erm/rxrx1_sf_results_ood_subsets_{algorithm}_{model_type}_{seed}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "direct_testing_evals = pd.DataFrame(direct_testing_results)\n",
    "direct_testing_evals.to_csv(\n",
    "    f\"suitability/results/sf_evals/erm/rxrx1_direct_testing_results_ood_subsets_{algorithm}_{model_type}_{seed}.csv\",\n",
    "    index=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID SPLIT SUBSET EVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('id_test', \"{'cell_type': 'HEPG2'}\"), ('id_test', \"{'cell_type': 'HUVEC'}\"), ('id_test', \"{'cell_type': 'RPE'}\"), ('id_test', \"{'cell_type': 'U2OS'}\")])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HEPG2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▎                                                               | 1/4 [01:47<05:21, 107.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HUVEC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 2/4 [03:42<03:44, 112.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'RPE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████▊                     | 3/4 [05:29<01:49, 109.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'U2OS'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [07:14<00:00, 108.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('id_test', \"{'cell_type': 'HEPG2'}\"), ('id_test', \"{'cell_type': 'HUVEC'}\"), ('id_test', \"{'cell_type': 'RPE'}\"), ('id_test', \"{'cell_type': 'U2OS'}\")])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HEPG2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▎                                                               | 1/4 [01:47<05:23, 107.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HUVEC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 2/4 [03:42<03:43, 111.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'RPE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████▊                     | 3/4 [05:29<01:49, 109.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'U2OS'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [07:14<00:00, 108.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('id_test', \"{'cell_type': 'HEPG2'}\"), ('id_test', \"{'cell_type': 'HUVEC'}\"), ('id_test', \"{'cell_type': 'RPE'}\"), ('id_test', \"{'cell_type': 'U2OS'}\")])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HEPG2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▎                                                               | 1/4 [01:47<05:23, 107.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'HUVEC'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▌                                          | 2/4 [03:41<03:43, 111.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'RPE'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████▊                     | 3/4 [05:29<01:49, 109.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'cell_type': 'U2OS'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [07:13<00:00, 108.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter\n",
    "from suitability.filter.tests import non_inferiority_ttest\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"rxrx1\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"ERM\"\n",
    "model_type = \"last\"\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "# Load the features\n",
    "    feature_cache_file = (\n",
    "        f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    "    )\n",
    "    with open(feature_cache_file, \"rb\") as f:\n",
    "        full_feature_dict = pickle.load(f)\n",
    "\n",
    "    # Load the split indices\n",
    "    split_cache_file = f\"suitability/results/split_indices/{data_name}.pkl\"\n",
    "    with open(split_cache_file, \"rb\") as f:\n",
    "        split_dict = pickle.load(f)\n",
    "\n",
    "    all_keys = list(split_dict.keys())\n",
    "    for key in all_keys:\n",
    "        if key[0] == 'test' or key[0] == 'val':\n",
    "            del split_dict[key]\n",
    "\n",
    "    print(split_dict.keys())\n",
    "\n",
    "    # Define suitability filter and experiment parameters\n",
    "    classifiers = [\n",
    "        \"logistic_regression\"\n",
    "    ]  # \"logistic_regression\", \"svm\", \"random_forest\", \"gradient_boosting\", \"mlp\", \"decision_tree\"]\n",
    "    margins = [0, 0.005, 0.01, 0.05]\n",
    "    normalize = True\n",
    "    calibrated = True\n",
    "    sf_results = []\n",
    "    direct_testing_results = []\n",
    "    feature_subsets = [\n",
    "        [0],\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [5],\n",
    "        [6],\n",
    "        [7],\n",
    "        [8],\n",
    "        [9],\n",
    "        [10],\n",
    "        [11],\n",
    "        # [4, 11],\n",
    "        # [4, 11, 8],\n",
    "        # [4, 11, 8, 6],\n",
    "        # [4, 11, 8, 6, 2],\n",
    "        # [4, 11, 8, 6, 2, 1],\n",
    "        # [4, 11, 8, 6, 2, 1, 0],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10, 5],\n",
    "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    ]\n",
    "    num_fold_arr = [15]\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    for user_split_name, user_filter in tqdm(split_dict.keys()):\n",
    "        print(f\"Evaluating user split: {user_split_name} with filter {user_filter}\")\n",
    "\n",
    "        # Get user split indices\n",
    "        user_split_indices = split_dict[(user_split_name, user_filter)]\n",
    "\n",
    "        # Get user split features and correctness\n",
    "        all_features, all_corr = full_feature_dict[user_split_name]\n",
    "        user_features = all_features[user_split_indices]\n",
    "        user_corr = all_corr[user_split_indices]\n",
    "        user_size = len(user_corr)\n",
    "        user_acc = np.mean(user_corr)\n",
    "\n",
    "        # Re-partition remaining data into folds\n",
    "        remaining_indices = np.setdiff1d(np.arange(len(all_corr)), user_split_indices)\n",
    "        source_features = all_features[remaining_indices]\n",
    "        source_corr = all_corr[remaining_indices]\n",
    "\n",
    "        for num_folds in num_fold_arr:\n",
    "            source_fold_size = len(source_corr) // num_folds\n",
    "            indices = np.arange(len(source_corr))\n",
    "            np.random.shuffle(indices)\n",
    "            fold_indices = [\n",
    "                indices[i * source_fold_size : (i + 1) * source_fold_size]\n",
    "                for i in range(num_folds)\n",
    "            ]\n",
    "\n",
    "            for i, reg_indices in enumerate(fold_indices):\n",
    "                reg_features = source_features[reg_indices]\n",
    "                reg_corr = source_corr[reg_indices]\n",
    "                reg_size = len(reg_corr)\n",
    "                reg_acc = np.mean(reg_corr)\n",
    "\n",
    "                for j, test_indices in enumerate(fold_indices):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    test_features = source_features[test_indices]\n",
    "                    test_corr = source_corr[test_indices]\n",
    "                    test_size = len(test_corr)\n",
    "                    test_acc = np.mean(test_corr)\n",
    "\n",
    "                    for classifier in classifiers:\n",
    "                        for feature_subset in feature_subsets:\n",
    "                            suitability_filter = SuitabilityFilter(\n",
    "                                test_features,\n",
    "                                test_corr,\n",
    "                                reg_features,\n",
    "                                reg_corr,\n",
    "                                device,\n",
    "                                normalize=normalize,\n",
    "                                feature_subset=feature_subset,\n",
    "                            )\n",
    "                            suitability_filter.train_classifier(\n",
    "                                calibrated=calibrated, classifier=classifier\n",
    "                            )\n",
    "\n",
    "                            for margin in margins:\n",
    "                                # Test suitability filter\n",
    "                                sf_test = suitability_filter.suitability_test(\n",
    "                                    user_features=user_features, margin=margin\n",
    "                                )\n",
    "                                p_value = sf_test[\"p_value\"]\n",
    "                                ground_truth = user_acc >= test_acc - margin\n",
    "\n",
    "                                sf_results.append(\n",
    "                                    {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"seed\": seed,\n",
    "                                        \"model_type\": model_type,\n",
    "                                        \"normalize\": normalize,\n",
    "                                        \"calibrated\": calibrated,\n",
    "                                        \"margin\": margin,\n",
    "                                        \"reg_fold\": i,\n",
    "                                        \"reg_size\": reg_size,\n",
    "                                        \"reg_acc\": reg_acc,\n",
    "                                        \"test_fold\": j,\n",
    "                                        \"test_size\": test_size,\n",
    "                                        \"test_acc\": test_acc,\n",
    "                                        \"user_split\": user_split_name,\n",
    "                                        \"user_filter\": user_filter,\n",
    "                                        \"user_size\": user_size,\n",
    "                                        \"user_acc\": user_acc,\n",
    "                                        \"p_value\": p_value,\n",
    "                                        \"ground_truth\": ground_truth,\n",
    "                                        \"classifier\": classifier,\n",
    "                                        \"feature_subset\": feature_subset,\n",
    "                                        \"acc_diff\": user_acc - test_acc,\n",
    "                                        \"acc_diff_adjusted\": user_acc + margin - test_acc,\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "                                # Run non-inferiority test on features directly\n",
    "                                if (\n",
    "                                    len(feature_subset) == 1\n",
    "                                    and margin == 0\n",
    "                                    and classifier == \"logistic_regression\"\n",
    "                                    and (j == 0 or (i == 0 and j == 1))\n",
    "                                ):\n",
    "                                    test_feature_subset = test_features[:, feature_subset].flatten()\n",
    "                                    user_feature_subset = user_features[:, feature_subset].flatten()\n",
    "                                    test_1 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=True,\n",
    "                                    )\n",
    "                                    test_2 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=False,\n",
    "                                    )\n",
    "                                    direct_testing_results.append(\n",
    "                                        {\n",
    "                                            \"data_name\": data_name,\n",
    "                                            \"algorithm\": algorithm,\n",
    "                                            \"seed\": seed,\n",
    "                                            \"model_type\": model_type,\n",
    "                                            \"test_fold\": j,\n",
    "                                            \"test_size\": test_size,\n",
    "                                            \"test_acc\": test_acc,\n",
    "                                            \"user_split\": user_split_name,\n",
    "                                            \"user_filter\": user_filter,\n",
    "                                            \"user_size\": user_size,\n",
    "                                            \"user_acc\": user_acc,\n",
    "                                            \"p_value_increase_good\": test_1[\"p_value\"],\n",
    "                                            \"p_value_decrease_good\": test_2[\"p_value\"],\n",
    "                                            \"ground_truth\": ground_truth,\n",
    "                                            \"feature_subset\": feature_subset,\n",
    "                                            \"acc_diff\": user_acc - test_acc,\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "    # Save results\n",
    "    sf_evals = pd.DataFrame(sf_results)\n",
    "    sf_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/erm/rxrx1_sf_results_id_subsets_{algorithm}_{model_type}_{seed}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    direct_testing_evals = pd.DataFrame(direct_testing_results)\n",
    "    direct_testing_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/erm/rxrx1_direct_testing_results_id_subsets_{algorithm}_{model_type}_{seed}.csv\",\n",
    "        index=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
