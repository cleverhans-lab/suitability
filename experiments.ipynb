{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import auc, precision_recall_curve, roc_curve\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter import suitability\n",
    "\n",
    "importlib.reload(suitability)\n",
    "\n",
    "from suitability.filter.evals import split_dataset_into_folds\n",
    "from suitability.filter.suitability import SuitabilityFilter\n",
    "\n",
    "random.seed(32)\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fmow for split id_\n",
      "Test size: 5742, Regressor size: 5741, User data size: 11327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_4117312/1729538463.py:113: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_sf = pd.concat(\n",
      "/tmp/ipykernel_4117312/1729538463.py:151: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_feat = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fmow for split \n",
      "Test size: 9958, Regressor size: 9957, User data size: 22108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/mfsnic/u/apouget/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "datasets_to_test = [\"fmow\", \"civilcomments\", \"rxrx1\", \"amazon\"] # \"iwildcam\"\n",
    "splits_to_test = [\"id_\", \"\"]\n",
    "step_size = 0.01\n",
    "num_random_tries = 100\n",
    "\n",
    "df_sf = pd.DataFrame(columns=[\"Dataset\", \"Split\", \"ROC AUC\", \"PR AUC\"])\n",
    "df_feat = pd.DataFrame(\n",
    "    columns=[\"Dataset\", \"Split\", \"Feature\", \"Type\", \"ROC AUC\", \"PR AUC\"]\n",
    ")\n",
    "\n",
    "\n",
    "def compute_roc_pr_auc(p_vals, ground_truth):\n",
    "    roc_auc = auc(*roc_curve(ground_truth.flatten(), p_vals.flatten())[:2])\n",
    "    precision, recall, _ = precision_recall_curve(\n",
    "        ground_truth.flatten(), p_vals.flatten()\n",
    "    )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return roc_auc, pr_auc\n",
    "\n",
    "\n",
    "for data_name in datasets_to_test:\n",
    "    for split in splits_to_test:\n",
    "        if data_name == \"civilcomments\" and split == \"id_\":\n",
    "            continue\n",
    "        print(f\"Testing {data_name} for split {split}\")\n",
    "\n",
    "        # Get data\n",
    "        dataset_val = get_wilds_dataset(\n",
    "            data_name,\n",
    "            root_dir,\n",
    "            split + \"val\",\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "        ).dataset\n",
    "        test, regressor = random_split(dataset_val, [0.5, 0.5])\n",
    "        test_data = DataLoader(test, batch_size=64, shuffle=False, num_workers=4)\n",
    "        regressor_data = DataLoader(\n",
    "            regressor, batch_size=64, shuffle=True, num_workers=4\n",
    "        )\n",
    "        user_data = get_wilds_dataset(\n",
    "            data_name,\n",
    "            root_dir,\n",
    "            split + \"test\",\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Test size: {len(test_data.dataset)}, Regressor size: {len(regressor_data.dataset)}, User data size: {len(user_data.dataset)}\"\n",
    "        )\n",
    "\n",
    "        # Get model\n",
    "        model = get_wilds_model(data_name, root_dir, algorithm=\"ERM\")\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Construct suitability filter\n",
    "        suitability_filter = SuitabilityFilter(model, test_data, regressor_data, device)\n",
    "        test_features, test_corr = suitability_filter.get_features(test_data)\n",
    "        suitability_filter.train_regressor()\n",
    "        all_user_features, all_user_corr = suitability_filter.get_features(user_data)\n",
    "\n",
    "        # Evaluate suitability\n",
    "        test_acc = np.mean(test_corr)\n",
    "        target_accuracies = np.arange(\n",
    "            test_acc - step_size / 2 - 4 * step_size,\n",
    "            test_acc + step_size / 2 + 5 * step_size,\n",
    "            step_size,\n",
    "        )\n",
    "        num_acc_folds = len(target_accuracies)\n",
    "\n",
    "        corrs = np.zeros((num_random_tries, num_acc_folds))\n",
    "        p_vals_sf = np.zeros((num_random_tries, num_acc_folds))\n",
    "        p_vals_feat = np.zeros(\n",
    "            (np.shape(all_user_features)[1], num_random_tries, num_acc_folds)\n",
    "        )\n",
    "        p_vals_feat_reg = np.zeros(\n",
    "            (np.shape(all_user_features)[1], num_random_tries, num_acc_folds)\n",
    "        )\n",
    "\n",
    "        for j in range(num_random_tries):\n",
    "            folds, actual_accuracies = split_dataset_into_folds(\n",
    "                all_user_corr, target_accuracies=target_accuracies\n",
    "            )\n",
    "            corrs[j] = np.array(actual_accuracies)\n",
    "\n",
    "            for i, fold_indices in enumerate(folds):\n",
    "                user_features = all_user_features[fold_indices]\n",
    "                p_vals_sf[j, i] = suitability_filter.suitability_test(\n",
    "                    user_features=user_features, margin=0\n",
    "                )[\"p_value\"]\n",
    "                feat_test = suitability_filter.suitability_test_for_individual_features(\n",
    "                    user_features=user_features\n",
    "                )\n",
    "                for fi, test in enumerate(feat_test):\n",
    "                    p_vals_feat[fi, j, i] = test[\"p_value\"]\n",
    "                    p_vals_feat_reg[fi, j, i] = (\n",
    "                        suitability_filter.suitability_test_for_feature_subset(\n",
    "                            feature_subset=[fi], user_features=user_features\n",
    "                        )[\"p_value\"]\n",
    "                    )\n",
    "\n",
    "        # Compute AUCs\n",
    "        ground_truth = corrs >= np.mean(test_corr)\n",
    "\n",
    "        # Compute and store suitability filter AUC values\n",
    "        roc_auc_sf, pr_auc_sf = compute_roc_pr_auc(-p_vals_sf, ground_truth)\n",
    "        df_sf = pd.concat(\n",
    "            [\n",
    "                df_sf,\n",
    "                pd.DataFrame(\n",
    "                    [[data_name, split, roc_auc_sf, pr_auc_sf]],\n",
    "                    columns=[\"Dataset\", \"Split\", \"ROC AUC\", \"PR AUC\"],\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        features = np.array(\n",
    "            [\n",
    "                \"Conf Max\",\n",
    "                \"Conf Std\",\n",
    "                \"Conf Entropy\",\n",
    "                \"Logit Mean\",\n",
    "                \"Logit Max\",\n",
    "                \"Logit Std\",\n",
    "                \"Logit Top 2 Diff\",\n",
    "                \"Loss\",\n",
    "                \"Margin Loss\",\n",
    "                \"Class Conf Ratio\",\n",
    "                \"Top-k Conf Sum\",\n",
    "                \"Energy\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Compute AUCs for each feature\n",
    "        for fi, feature in enumerate(features):\n",
    "            roc_auc_feat, pr_auc_feat = compute_roc_pr_auc(\n",
    "                (\n",
    "                    -p_vals_feat[fi, :, :]\n",
    "                    if fi in [0, 1, 4, 6, 9, 10]\n",
    "                    else p_vals_feat[fi, :, :]\n",
    "                ),\n",
    "                ground_truth,\n",
    "            )\n",
    "            df_feat = pd.concat(\n",
    "                [\n",
    "                    df_feat,\n",
    "                    pd.DataFrame(\n",
    "                        [\n",
    "                            [\n",
    "                                data_name,\n",
    "                                split,\n",
    "                                feature,\n",
    "                                \"Feature\",\n",
    "                                roc_auc_feat,\n",
    "                                pr_auc_feat,\n",
    "                            ]\n",
    "                        ],\n",
    "                        columns=[\n",
    "                            \"Dataset\",\n",
    "                            \"Split\",\n",
    "                            \"Feature\",\n",
    "                            \"Type\",\n",
    "                            \"ROC AUC\",\n",
    "                            \"PR AUC\",\n",
    "                        ],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "            roc_auc_feat_reg, pr_auc_feat_reg = compute_roc_pr_auc(\n",
    "                -p_vals_feat_reg[fi, :, :], ground_truth\n",
    "            )\n",
    "            df_feat = pd.concat(\n",
    "                [\n",
    "                    df_feat,\n",
    "                    pd.DataFrame(\n",
    "                        [\n",
    "                            [\n",
    "                                data_name,\n",
    "                                split,\n",
    "                                feature,\n",
    "                                \"Feature (Reg)\",\n",
    "                                roc_auc_feat_reg,\n",
    "                                pr_auc_feat_reg,\n",
    "                            ]\n",
    "                        ],\n",
    "                        columns=[\n",
    "                            \"Dataset\",\n",
    "                            \"Split\",\n",
    "                            \"Feature\",\n",
    "                            \"Type\",\n",
    "                            \"ROC AUC\",\n",
    "                            \"PR AUC\",\n",
    "                        ],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "# Save DataFrames to CSV (optional)\n",
    "df_sf.to_csv(\"suitability/results/wilds_suitability_filter_auc.csv\", index=False)\n",
    "df_feat.to_csv(\"suitability/results/wilds_feature_auc.csv\", index=False)\n",
    "\n",
    "print(df_sf)\n",
    "print(df_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
