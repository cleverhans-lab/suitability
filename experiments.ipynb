{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suitability Filter Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import torch\n",
    "from examples.models.initializer import initialize_torchvision_model\n",
    "\n",
    "import suitability.filter.tests as ftests\n",
    "from suitability.datasets.wilds import get_wilds_dataset\n",
    "from suitability.filter import suitability\n",
    "\n",
    "importlib.reload(suitability)\n",
    "\n",
    "from suitability.filter.suitability import SuitabilityFilter\n",
    "\n",
    "random.seed(32)\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_from_state_dict(state_dict, prefix=\"model.\"):\n",
    "    \"\"\"\n",
    "    Remove the prefix from the keys in state_dict if it exists.\n",
    "    \"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_state_dict[k[len(prefix) :]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/mfsnic/u/apouget/data/\"\n",
    "dataset_name = \"fmow\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = initialize_torchvision_model(\"densenet121\", d_out=62, pretrained=True)\n",
    "state_dict = remove_prefix_from_state_dict(\n",
    "    torch.load(\n",
    "        f\"/mfsnic/u/apouget/experiments/{dataset_name}/{dataset_name}_seed:0_epoch:last_model.pth\"\n",
    "    )[\"algorithm\"]\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_data = get_wilds_dataset(\n",
    "    dataset_name,\n",
    "    root_dir,\n",
    "    \"val\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pre_filter={\"region\": \"Asia\"},\n",
    ")\n",
    "regressor_data = get_wilds_dataset(\n",
    "    dataset_name,\n",
    "    root_dir,\n",
    "    \"val\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pre_filter={\"region\": \"Americas\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize suitability filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitability_filter = SuitabilityFilter(model, test_data, regressor_data, device)\n",
    "test_features, test_corr = suitability_filter.get_features(test_data)\n",
    "suitability_filter.train_regressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the suitability filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-the-wild evaluation and comparison to AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\"Asia\", \"Europe\", \"Africa\", \"Americas\", \"Oceania\"]\n",
    "\n",
    "# Construct suitability filter\n",
    "features = {}\n",
    "correctness = {}\n",
    "acs = {}\n",
    "\n",
    "for region in REGIONS:\n",
    "    user_data = get_wilds_dataset(\n",
    "        dataset_name,\n",
    "        root_dir,\n",
    "        \"test\",\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter={\"region\": region},\n",
    "    )\n",
    "\n",
    "    user_features, user_corr = suitability_filter.get_features(user_data)\n",
    "    acs[region] = np.mean(user_features, axis=0)[1]\n",
    "    correctness[region] = user_corr\n",
    "    test = suitability_filter.suitability_test(user_features=user_features)\n",
    "\n",
    "    print(f\"--- Region {region}: {user_features.shape[0]} samples ---\")\n",
    "    print(\n",
    "        f\"{np.mean(user_corr) * 100:.2f}% correct (compared to {np.mean(test_corr) * 100:.2f}% for test)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"AC: {acs[region]:.4f}, test AC: {np.mean(test_features, axis=0)[1]:.4f} -> {'SUITABLE' if acs[region] >= np.mean(test_features, axis=0)[1] else 'NOT SUITABLE'}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Non-inferiority-test, p-value {test['p_value']:.4f} -> {'SUITABLE' if test['p_value']<=0.05 else 'NOT SUITABLE'}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP analysis for signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "shap_values = suitability_filter.calculate_shap_values()\n",
    "\n",
    "# To visualize (optional)\n",
    "shap.summary_plot(shap_values, suitability_filter.regressor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
