{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the suitability filter on FMoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter import suitability_efficient\n",
    "\n",
    "importlib.reload(suitability_efficient)\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter, get_sf_features\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & evaluate all possible splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_val_splits = [\n",
    "    (\"id_val\", {\"year\": 2002}),\n",
    "    (\"id_val\", {\"year\": 2003}),\n",
    "    (\"id_val\", {\"year\": 2004}),\n",
    "    (\"id_val\", {\"year\": 2005}),\n",
    "    (\"id_val\", {\"year\": 2006}),\n",
    "    (\"id_val\", {\"year\": 2007}),\n",
    "    (\"id_val\", {\"year\": 2008}),\n",
    "    (\"id_val\", {\"year\": 2009}),\n",
    "    (\"id_val\", {\"year\": 2010}),\n",
    "    (\"id_val\", {\"year\": 2011}),\n",
    "    (\"id_val\", {\"year\": 2012}),\n",
    "    (\"id_val\", {\"region\": \"Asia\"}),\n",
    "    (\"id_val\", {\"region\": \"Europe\"}),\n",
    "    (\"id_val\", {\"region\": \"Africa\"}),\n",
    "    (\"id_val\", {\"region\": \"Americas\"}),\n",
    "    (\"id_val\", {\"region\": \"Oceania\"}),\n",
    "]\n",
    "\n",
    "id_test_splits = [\n",
    "    (\"id_test\", {\"year\": 2002}),\n",
    "    (\"id_test\", {\"year\": 2003}),\n",
    "    (\"id_test\", {\"year\": 2004}),\n",
    "    (\"id_test\", {\"year\": 2005}),\n",
    "    (\"id_test\", {\"year\": 2006}),\n",
    "    (\"id_test\", {\"year\": 2007}),\n",
    "    (\"id_test\", {\"year\": 2008}),\n",
    "    (\"id_test\", {\"year\": 2009}),\n",
    "    (\"id_test\", {\"year\": 2010}),\n",
    "    (\"id_test\", {\"year\": 2011}),\n",
    "    (\"id_test\", {\"year\": 2012}),\n",
    "    (\"id_test\", {\"region\": \"Asia\"}),\n",
    "    (\"id_test\", {\"region\": \"Europe\"}),\n",
    "    (\"id_test\", {\"region\": \"Africa\"}),\n",
    "    (\"id_test\", {\"region\": \"Americas\"}),\n",
    "    (\"id_test\", {\"region\": \"Oceania\"}),\n",
    "]\n",
    "\n",
    "ood_val_splits = [\n",
    "    (\"val\", {\"year\": 2013}),\n",
    "    (\"val\", {\"year\": 2014}),\n",
    "    (\"val\", {\"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Asia\"}),\n",
    "    (\"val\", {\"region\": \"Europe\"}),\n",
    "    (\"val\", {\"region\": \"Africa\"}),\n",
    "    (\"val\", {\"region\": \"Americas\"}),\n",
    "    (\"val\", {\"region\": \"Oceania\"}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2015}),\n",
    "]\n",
    "\n",
    "ood_test_splits = [\n",
    "    (\"test\", {\"year\": 2016}),\n",
    "    (\"test\", {\"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\"}),\n",
    "    (\"test\", {\"region\": \"Europe\"}),\n",
    "    (\"test\", {\"region\": \"Africa\"}),\n",
    "    (\"test\", {\"region\": \"Americas\"}),\n",
    "    (\"test\", {\"region\": \"Oceania\"}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2017}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/u/apouget/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_wilds_model(data_name, root_dir, algorithm=\"ERM\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_splits = id_val_splits + id_test_splits + ood_val_splits + ood_test_splits\n",
    "\n",
    "results = pd.DataFrame(columns=[\"split\", \"year\", \"region\", \"num_samples\", \"accuracy\"])\n",
    "\n",
    "for split, pre_filter in all_splits:\n",
    "    data = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=pre_filter,\n",
    "    )\n",
    "    suitability_filter = SuitabilityFilter(model, data, data, device)\n",
    "    corr = suitability_filter.get_correct(data)\n",
    "\n",
    "    num_samples = len(data.dataset)\n",
    "    accuracy = np.mean(corr)\n",
    "    year = pre_filter.get(\"year\", \"ALL\")\n",
    "    region = pre_filter.get(\"region\", \"ALL\")\n",
    "    results = results._append(\n",
    "        {\n",
    "            \"split\": split,\n",
    "            \"year\": year,\n",
    "            \"region\": region,\n",
    "            \"num_samples\": num_samples,\n",
    "            \"accuracy\": accuracy,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "results.to_csv(\"suitability/results/data_splits/fmow_ERM_0_last.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate suitability filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid id splits: 16, number of valid ood splits: 30\n"
     ]
    }
   ],
   "source": [
    "valid_id_splits = [\n",
    "    (\"id_val\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_val\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_val\", {\"year\": [2010]}),\n",
    "    (\"id_val\", {\"year\": [2011]}),\n",
    "    (\"id_val\", {\"year\": [2012]}),\n",
    "    (\"id_val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"id_test\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_test\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_test\", {\"year\": [2010]}),\n",
    "    (\"id_test\", {\"year\": [2011]}),\n",
    "    (\"id_test\", {\"year\": [2012]}),\n",
    "    (\"id_test\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Americas\"]}),\n",
    "]\n",
    "\n",
    "valid_ood_splits = [\n",
    "    (\"val\", {\"year\": [2013]}),\n",
    "    (\"val\", {\"year\": [2014]}),\n",
    "    (\"val\", {\"year\": [2015]}),\n",
    "    (\"val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"val\", {\"region\": [\"Africa\"]}),\n",
    "    (\"val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"val\", {\"region\": [\"Oceania\"]}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2015}),\n",
    "    (\"test\", {\"year\": 2016}),\n",
    "    (\"test\", {\"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\"}),\n",
    "    (\"test\", {\"region\": \"Europe\"}),\n",
    "    (\"test\", {\"region\": \"Africa\"}),\n",
    "    (\"test\", {\"region\": \"Americas\"}),\n",
    "    (\"test\", {\"region\": \"Oceania\"}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2017}),\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Number of valid id splits: {len(valid_id_splits)}, number of valid ood splits: {len(valid_ood_splits)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate suitability filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter, get_sf_features\n",
    "\n",
    "cache_file_id_combined = \"suitability/results/features/fmow_ERM_last_0_combined_id.pkl\"\n",
    "if os.path.exists(cache_file_id_combined):\n",
    "    with open(cache_file_id_combined, \"rb\") as f:\n",
    "        features_id_combined = pickle.load(f)\n",
    "\n",
    "cache_file_id_individual = \"suitability/results/features/fmow_ERM_last_0_id.pkl\"\n",
    "if os.path.exists(cache_file_id_individual):\n",
    "    with open(cache_file_id_individual, \"rb\") as f:\n",
    "        features_id_individual = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.99883533e-01,  1.26985088e-01,  1.36794173e-03, -1.35100746e+01,\n",
       "        4.84576941e+00,  4.60921860e+00,  1.01284866e+01,  1.16460695e-04,\n",
       "       -1.01284847e+01,  2.50463672e+04,  9.99990404e-01, -4.84588575e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_id_individual[(\"id_test\", \"{'region': ['Asia']}\")][\"features\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_id_individual[(\"id_test\", \"{'region': ['Asia']}\")][\"indices\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.94658554,   0.1202942 ,   0.21097937, -14.761689  ,\n",
       "         1.6514555 ,   4.5276346 ,   2.8811173 ,   0.05489393,\n",
       "        -2.8811173 ,  17.834188  ,   0.9999731 ,  -1.7063494 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_id_combined[\"features\"][120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mfsnic/u/apouget/envs/test/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to device: cuda\n",
      "Computing features for split: id_val\n",
      "Computing features for split: id_test\n",
      "Computing features for split: val\n",
      "Computing features for split: test\n",
      "ID splits features computed\n",
      "Features saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from suitability.datasets.wilds import get_wilds_dataset, get_wilds_model\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter, get_sf_features\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"ERM\"\n",
    "model_type = \"last\"\n",
    "seed = 0\n",
    "model = get_wilds_model(\n",
    "    data_name, root_dir, algorithm=algorithm, seed=seed, model_type=model_type\n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded to device: {device}\")\n",
    "\n",
    "# Initialize results DataFrame\n",
    "features_cache_file = (\n",
    "    f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    ")\n",
    "valid_splits = [\"id_val\", \"id_test\", \"val\", \"test\"]\n",
    "splits_features_cache = {}\n",
    "\n",
    "# Precompute all data features\n",
    "for split_name in valid_splits:\n",
    "    print(f\"Computing features for split: {split_name}\")\n",
    "    dataset = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    splits_features_cache[split_name] = get_sf_features(dataset, model, device)\n",
    "print(\"ID splits features computed\")\n",
    "\n",
    "# Save feature cache\n",
    "with open(features_cache_file, \"wb\") as f:\n",
    "    pickle.dump(splits_features_cache, f)\n",
    "\n",
    "# Precompute all id split indices\n",
    "id_cache_file = f\"suitability/results/split_indices/{data_name}_id.pkl\"\n",
    "\n",
    "valid_id_splits = [\n",
    "    (\"id_val\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_val\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_val\", {\"year\": [2010]}),\n",
    "    (\"id_val\", {\"year\": [2011]}),\n",
    "    (\"id_val\", {\"year\": [2012]}),\n",
    "    (\"id_val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"id_test\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_test\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_test\", {\"year\": [2010]}),\n",
    "    (\"id_test\", {\"year\": [2011]}),\n",
    "    (\"id_test\", {\"year\": [2012]}),\n",
    "    (\"id_test\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Americas\"]}),\n",
    "]\n",
    "\n",
    "id_splits_indices_cache = {}\n",
    "for split_name, split_filter in valid_id_splits:\n",
    "    print(f\"Computing indices for split: {split_name} with filter: {split_filter}\")\n",
    "    dataset, indices = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=split_filter,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    id_splits_indices_cache[(split_name, str(split_filter))] = indices\n",
    "\n",
    "with open(id_cache_file, \"wb\") as f:\n",
    "    pickle.dump(id_splits_indices_cache, f)\n",
    "\n",
    "# Precompute all ood split indices\n",
    "ood_cache_file = f\"suitability/results/split_indices/{data_name}_ood.pkl\"\n",
    "\n",
    "valid_ood_splits = [\n",
    "    (\"val\", {\"year\": [2013]}),\n",
    "    (\"val\", {\"year\": [2014]}),\n",
    "    (\"val\", {\"year\": [2015]}),\n",
    "    (\"val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"val\", {\"region\": [\"Africa\"]}),\n",
    "    (\"val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"val\", {\"region\": [\"Oceania\"]}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2015}),\n",
    "    (\"test\", {\"year\": 2016}),\n",
    "    (\"test\", {\"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\"}),\n",
    "    (\"test\", {\"region\": \"Europe\"}),\n",
    "    (\"test\", {\"region\": \"Africa\"}),\n",
    "    (\"test\", {\"region\": \"Americas\"}),\n",
    "    (\"test\", {\"region\": \"Oceania\"}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2017}),\n",
    "]\n",
    "\n",
    "ood_splits_indices_cache = {}\n",
    "\n",
    "for split_name, split_filter in valid_ood_splits:\n",
    "    dataset, indices = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=split_filter,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    ood_splits_indices_cache[(split_name, str(split_filter))] = indices\n",
    "\n",
    "# Save cache\n",
    "with open(ood_cache_file, \"wb\") as f:\n",
    "    pickle.dump(ood_cache_file, f)\n",
    "print(\"Features saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('id_val', \"{'year': [2002, 2003, 2004, 2005, 2006]}\"), ('id_val', \"{'year': [2007, 2008, 2009]}\"), ('id_val', \"{'year': [2010]}\"), ('id_val', \"{'year': [2011]}\"), ('id_val', \"{'year': [2012]}\"), ('id_val', \"{'region': ['Asia']}\"), ('id_val', \"{'region': ['Europe']}\"), ('id_val', \"{'region': ['Americas']}\"), ('id_test', \"{'year': [2002, 2003, 2004, 2005, 2006]}\"), ('id_test', \"{'year': [2007, 2008, 2009]}\"), ('id_test', \"{'year': [2010]}\"), ('id_test', \"{'year': [2011]}\"), ('id_test', \"{'year': [2012]}\"), ('id_test', \"{'region': ['Asia']}\"), ('id_test', \"{'region': ['Europe']}\"), ('id_test', \"{'region': ['Americas']}\")])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "x = pickle.load(\n",
    "    open(\"/h/321/apouget/suitability/results/split_indices/fmow_id.pkl\", \"rb\")\n",
    ")\n",
    "print(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420\n"
     ]
    }
   ],
   "source": [
    "for a, b in x.keys():\n",
    "    indices = x[(a, b)]\n",
    "    break\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1420, 12)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "y = pickle.load(\n",
    "    open(\"/h/321/apouget/suitability/results/features/fmow_ERM_last_0.pkl\", \"rb\")\n",
    ")\n",
    "print(y[\"id_val\"][0][indices].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing indices for split: id_val with filter: {'year': [2002, 2003, 2004, 2005, 2006]}\n",
      "Computing indices for split: id_val with filter: {'year': [2007, 2008, 2009]}\n",
      "Computing indices for split: id_val with filter: {'year': [2010]}\n",
      "Computing indices for split: id_val with filter: {'year': [2011]}\n",
      "Computing indices for split: id_val with filter: {'year': [2012]}\n",
      "Computing indices for split: id_val with filter: {'region': ['Asia']}\n",
      "Computing indices for split: id_val with filter: {'region': ['Europe']}\n",
      "Computing indices for split: id_val with filter: {'region': ['Americas']}\n",
      "Computing indices for split: id_test with filter: {'year': [2002, 2003, 2004, 2005, 2006]}\n",
      "Computing indices for split: id_test with filter: {'year': [2007, 2008, 2009]}\n",
      "Computing indices for split: id_test with filter: {'year': [2010]}\n",
      "Computing indices for split: id_test with filter: {'year': [2011]}\n",
      "Computing indices for split: id_test with filter: {'year': [2012]}\n",
      "Computing indices for split: id_test with filter: {'region': ['Asia']}\n",
      "Computing indices for split: id_test with filter: {'region': ['Europe']}\n",
      "Computing indices for split: id_test with filter: {'region': ['Americas']}\n",
      "Features saved\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize results DataFrame\n",
    "cache_file = f\"suitability/results/split_indices/{data_name}_id.pkl\"\n",
    "\n",
    "valid_id_splits = [\n",
    "    (\"id_val\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_val\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_val\", {\"year\": [2010]}),\n",
    "    (\"id_val\", {\"year\": [2011]}),\n",
    "    (\"id_val\", {\"year\": [2012]}),\n",
    "    (\"id_val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"id_test\", {\"year\": [2002, 2003, 2004, 2005, 2006]}),\n",
    "    (\"id_test\", {\"year\": [2007, 2008, 2009]}),\n",
    "    (\"id_test\", {\"year\": [2010]}),\n",
    "    (\"id_test\", {\"year\": [2011]}),\n",
    "    (\"id_test\", {\"year\": [2012]}),\n",
    "    (\"id_test\", {\"region\": [\"Asia\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Europe\"]}),\n",
    "    (\"id_test\", {\"region\": [\"Americas\"]}),\n",
    "]\n",
    "\n",
    "splits_indices_cache = {}\n",
    "\n",
    "\n",
    "# Precompute all data features\n",
    "for split_name, split_filter in valid_id_splits:\n",
    "    print(f\"Computing indices for split: {split_name} with filter: {split_filter}\")\n",
    "    dataset, indices = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=split_filter,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    splits_indices_cache[(split_name, str(split_filter))] = indices\n",
    "\n",
    "# Save cache\n",
    "with open(cache_file, \"wb\") as f:\n",
    "    pickle.dump(splits_indices_cache, f)\n",
    "print(\"Features saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing indices for split: val with filter: {'year': [2013]}\n",
      "Computing indices for split: val with filter: {'year': [2014]}\n",
      "Computing indices for split: val with filter: {'year': [2015]}\n",
      "Computing indices for split: val with filter: {'region': ['Asia']}\n",
      "Computing indices for split: val with filter: {'region': ['Europe']}\n",
      "Computing indices for split: val with filter: {'region': ['Africa']}\n",
      "Computing indices for split: val with filter: {'region': ['Americas']}\n",
      "Computing indices for split: val with filter: {'region': ['Oceania']}\n",
      "Computing indices for split: val with filter: {'region': 'Europe', 'year': 2013}\n",
      "Computing indices for split: val with filter: {'region': 'Europe', 'year': 2014}\n",
      "Computing indices for split: val with filter: {'region': 'Europe', 'year': 2015}\n",
      "Computing indices for split: val with filter: {'region': 'Asia', 'year': 2013}\n",
      "Computing indices for split: val with filter: {'region': 'Asia', 'year': 2014}\n",
      "Computing indices for split: val with filter: {'region': 'Asia', 'year': 2015}\n",
      "Computing indices for split: val with filter: {'region': 'Americas', 'year': 2013}\n",
      "Computing indices for split: val with filter: {'region': 'Americas', 'year': 2014}\n",
      "Computing indices for split: val with filter: {'region': 'Americas', 'year': 2015}\n",
      "Computing indices for split: test with filter: {'year': 2016}\n",
      "Computing indices for split: test with filter: {'year': 2017}\n",
      "Computing indices for split: test with filter: {'region': 'Asia'}\n",
      "Computing indices for split: test with filter: {'region': 'Europe'}\n",
      "Computing indices for split: test with filter: {'region': 'Africa'}\n",
      "Computing indices for split: test with filter: {'region': 'Americas'}\n",
      "Computing indices for split: test with filter: {'region': 'Oceania'}\n",
      "Computing indices for split: test with filter: {'region': 'Europe', 'year': 2016}\n",
      "Computing indices for split: test with filter: {'region': 'Europe', 'year': 2017}\n",
      "Computing indices for split: test with filter: {'region': 'Asia', 'year': 2016}\n",
      "Computing indices for split: test with filter: {'region': 'Asia', 'year': 2017}\n",
      "Computing indices for split: test with filter: {'region': 'Americas', 'year': 2016}\n",
      "Computing indices for split: test with filter: {'region': 'Americas', 'year': 2017}\n",
      "Features saved\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize results DataFrame\n",
    "cache_file = f\"suitability/results/split_indices/{data_name}_ood.pkl\"\n",
    "\n",
    "valid_ood_splits = [\n",
    "    (\"val\", {\"year\": [2013]}),\n",
    "    (\"val\", {\"year\": [2014]}),\n",
    "    (\"val\", {\"year\": [2015]}),\n",
    "    (\"val\", {\"region\": [\"Asia\"]}),\n",
    "    (\"val\", {\"region\": [\"Europe\"]}),\n",
    "    (\"val\", {\"region\": [\"Africa\"]}),\n",
    "    (\"val\", {\"region\": [\"Americas\"]}),\n",
    "    (\"val\", {\"region\": [\"Oceania\"]}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Europe\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Asia\", \"year\": 2015}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2013}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2014}),\n",
    "    (\"val\", {\"region\": \"Americas\", \"year\": 2015}),\n",
    "    (\"test\", {\"year\": 2016}),\n",
    "    (\"test\", {\"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\"}),\n",
    "    (\"test\", {\"region\": \"Europe\"}),\n",
    "    (\"test\", {\"region\": \"Africa\"}),\n",
    "    (\"test\", {\"region\": \"Americas\"}),\n",
    "    (\"test\", {\"region\": \"Oceania\"}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Europe\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Asia\", \"year\": 2017}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2016}),\n",
    "    (\"test\", {\"region\": \"Americas\", \"year\": 2017}),\n",
    "]\n",
    "\n",
    "splits_indices_cache = {}\n",
    "\n",
    "\n",
    "# Precompute all data features\n",
    "for split_name, split_filter in valid_ood_splits:\n",
    "    print(f\"Computing indices for split: {split_name} with filter: {split_filter}\")\n",
    "    dataset, indices = get_wilds_dataset(\n",
    "        data_name,\n",
    "        root_dir,\n",
    "        split_name,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pre_filter=split_filter,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    splits_indices_cache[(split_name, str(split_filter))] = indices\n",
    "\n",
    "# Save cache\n",
    "with open(cache_file, \"wb\") as f:\n",
    "    pickle.dump(splits_indices_cache, f)\n",
    "print(\"Features saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID SPLIT SUBSET EVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                            | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████▎                                                                                                            | 1/16 [01:36<24:06, 96.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▌                                                                                                     | 2/16 [03:13<22:35, 96.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▊                                                                                              | 3/16 [04:51<21:02, 97.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████                                                                                       | 4/16 [06:28<19:28, 97.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████▎                                                                               | 5/16 [08:06<17:52, 97.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████▌                                                                        | 6/16 [09:44<16:16, 97.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████▊                                                                 | 7/16 [11:23<14:42, 98.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████                                                          | 8/16 [13:01<13:03, 97.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████████████████▎                                                  | 9/16 [14:38<11:24, 97.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████▉                                           | 10/16 [16:15<09:45, 97.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████████████████████████                                    | 11/16 [17:53<08:08, 97.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 12/16 [19:31<06:30, 97.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████▍                     | 13/16 [21:09<04:53, 97.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 14/16 [22:47<03:15, 97.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 15/16 [24:26<01:38, 98.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [26:04<00:00, 97.78s/it]\n",
      "  0%|                                                                                                                            | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████▎                                                                                                            | 1/16 [01:37<24:16, 97.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▌                                                                                                     | 2/16 [03:13<22:37, 96.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▊                                                                                              | 3/16 [04:51<21:04, 97.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████                                                                                       | 4/16 [06:29<19:28, 97.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████████████▎                                                                               | 5/16 [08:06<17:53, 97.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████▌                                                                        | 6/16 [09:44<16:14, 97.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████▊                                                                 | 7/16 [11:23<14:41, 97.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████                                                          | 8/16 [13:01<13:03, 97.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████████████████▎                                                  | 9/16 [14:37<11:23, 97.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████████████████▉                                           | 10/16 [16:15<09:45, 97.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████████████████████████                                    | 11/16 [17:52<08:07, 97.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████▎                            | 12/16 [19:30<06:30, 97.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████▍                     | 13/16 [21:08<04:52, 97.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 14/16 [22:45<03:15, 97.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 15/16 [24:24<01:38, 98.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [26:02<00:00, 97.67s/it]\n",
      "  0%|                                                                                                                                    | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████▊                                                                                                                    | 1/16 [01:39<24:45, 99.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████▌                                                                                                            | 2/16 [03:16<22:54, 98.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████▎                                                                                                    | 3/16 [04:54<21:14, 98.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████                                                                                             | 4/16 [06:32<19:36, 98.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████████▊                                                                                     | 5/16 [08:10<17:58, 98.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████████▌                                                                             | 6/16 [09:48<16:19, 97.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████████▎                                                                     | 7/16 [11:27<14:45, 98.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████                                                              | 8/16 [13:05<13:06, 98.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2002, 2003, 2004, 2005, 2006]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████████████████████▊                                                      | 9/16 [14:42<11:25, 97.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2007, 2008, 2009]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████████████████████████████▉                                              | 10/16 [16:19<09:45, 97.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2010]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████████████▌                                      | 11/16 [17:57<08:08, 97.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2011]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████▎                              | 12/16 [19:35<06:30, 97.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'year': [2012]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 13/16 [21:17<04:57, 99.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 14/16 [23:02<03:21, 100.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 15/16 [24:47<01:42, 102.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: id_test with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [26:32<00:00, 99.55s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter\n",
    "from suitability.filter.tests import non_inferiority_ttest\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"ERM\"\n",
    "model_type = \"last\"\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    # Load the features\n",
    "    feature_cache_file = (\n",
    "        f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    "    )\n",
    "    with open(feature_cache_file, \"rb\") as f:\n",
    "        full_feature_dict = pickle.load(f)\n",
    "    id_feature_dict = {}\n",
    "    id_feature_dict[\"id_val\"] = full_feature_dict[\"id_val\"]\n",
    "    id_feature_dict[\"id_test\"] = full_feature_dict[\"id_test\"]\n",
    "\n",
    "    # Load the split indices\n",
    "    split_cache_file = f\"suitability/results/split_indices/{data_name}_id.pkl\"\n",
    "    with open(split_cache_file, \"rb\") as f:\n",
    "        id_split_dict = pickle.load(f)\n",
    "\n",
    "    # Define suitability filter and experiment parameters\n",
    "    classifiers = [\n",
    "        \"logistic_regression\"\n",
    "    ]  # \"logistic_regression\", \"svm\", \"random_forest\", \"gradient_boosting\", \"mlp\", \"decision_tree\"]\n",
    "    margins = [0, 0.005, 0.01, 0.05]\n",
    "    normalize = True\n",
    "    calibrated = True\n",
    "    sf_results = []\n",
    "    direct_testing_results = []\n",
    "    feature_subsets = [\n",
    "        [0],\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [5],\n",
    "        [6],\n",
    "        [7],\n",
    "        [8],\n",
    "        [9],\n",
    "        [10],\n",
    "        [11],\n",
    "        # [4, 11],\n",
    "        # [4, 11, 8],\n",
    "        # [4, 11, 8, 6],\n",
    "        # [4, 11, 8, 6, 2],\n",
    "        # [4, 11, 8, 6, 2, 1],\n",
    "        # [4, 11, 8, 6, 2, 1, 0],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10, 5],\n",
    "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    ]\n",
    "    num_fold_arr = [15]\n",
    "\n",
    "    # Main loop\n",
    "    for user_split_name, user_filter in tqdm(id_split_dict.keys()):\n",
    "        print(f\"Evaluating user split: {user_split_name} with filter {user_filter}\")\n",
    "\n",
    "        # Get user split indices\n",
    "        user_split_indices = id_split_dict[(user_split_name, user_filter)]\n",
    "\n",
    "        # Get user split features and correctness\n",
    "        all_features, all_corr = id_feature_dict[user_split_name]\n",
    "        user_features = all_features[user_split_indices]\n",
    "        user_corr = all_corr[user_split_indices]\n",
    "        user_size = len(user_corr)\n",
    "        user_acc = np.mean(user_corr)\n",
    "\n",
    "        # Re-partition remaining data into folds\n",
    "        remaining_indices = np.setdiff1d(np.arange(len(all_corr)), user_split_indices)\n",
    "        remaining_features = all_features[remaining_indices]\n",
    "        remaining_corr = all_corr[remaining_indices]\n",
    "        if user_split_name == \"id_val\":\n",
    "            other_split_name = \"id_test\"\n",
    "        elif user_split_name == \"id_test\":\n",
    "            other_split_name = \"id_val\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid split name: {user_split_name}\")\n",
    "        additional_features, additional_corr = id_feature_dict[other_split_name]\n",
    "        source_features = np.concatenate([remaining_features, additional_features], axis=0)\n",
    "        source_corr = np.concatenate([remaining_corr, additional_corr], axis=0)\n",
    "\n",
    "        for num_folds in num_fold_arr:\n",
    "            source_fold_size = len(source_corr) // num_folds\n",
    "            indices = np.arange(len(source_corr))\n",
    "            np.random.shuffle(indices)\n",
    "            fold_indices = [\n",
    "                indices[i * source_fold_size : (i + 1) * source_fold_size]\n",
    "                for i in range(num_folds)\n",
    "            ]\n",
    "\n",
    "            for i, reg_indices in enumerate(fold_indices):\n",
    "                reg_features = source_features[reg_indices]\n",
    "                reg_corr = source_corr[reg_indices]\n",
    "                reg_size = len(reg_corr)\n",
    "                reg_acc = np.mean(reg_corr)\n",
    "\n",
    "                for j, test_indices in enumerate(fold_indices):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    test_features = source_features[test_indices]\n",
    "                    test_corr = source_corr[test_indices]\n",
    "                    test_size = len(test_corr)\n",
    "                    test_acc = np.mean(test_corr)\n",
    "\n",
    "                    for classifier in classifiers:\n",
    "                        for feature_subset in feature_subsets:\n",
    "                            suitability_filter = SuitabilityFilter(\n",
    "                                test_features,\n",
    "                                test_corr,\n",
    "                                reg_features,\n",
    "                                reg_corr,\n",
    "                                device,\n",
    "                                normalize=normalize,\n",
    "                                feature_subset=feature_subset,\n",
    "                            )\n",
    "                            suitability_filter.train_classifier(\n",
    "                                calibrated=calibrated, classifier=classifier\n",
    "                            )\n",
    "\n",
    "                            for margin in margins:\n",
    "                                # Test suitability filter\n",
    "                                sf_test = suitability_filter.suitability_test(\n",
    "                                    user_features=user_features, margin=margin\n",
    "                                )\n",
    "                                p_value = sf_test[\"p_value\"]\n",
    "                                ground_truth = user_acc >= test_acc - margin\n",
    "\n",
    "                                sf_results.append(\n",
    "                                    {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"seed\": seed,\n",
    "                                        \"model_type\": model_type,\n",
    "                                        \"normalize\": normalize,\n",
    "                                        \"calibrated\": calibrated,\n",
    "                                        \"margin\": margin,\n",
    "                                        \"reg_fold\": i,\n",
    "                                        \"reg_size\": reg_size,\n",
    "                                        \"reg_acc\": reg_acc,\n",
    "                                        \"test_fold\": j,\n",
    "                                        \"test_size\": test_size,\n",
    "                                        \"test_acc\": test_acc,\n",
    "                                        \"user_split\": user_split_name,\n",
    "                                        \"user_filter\": user_filter,\n",
    "                                        \"user_size\": user_size,\n",
    "                                        \"user_acc\": user_acc,\n",
    "                                        \"p_value\": p_value,\n",
    "                                        \"ground_truth\": ground_truth,\n",
    "                                        \"classifier\": classifier,\n",
    "                                        \"feature_subset\": feature_subset,\n",
    "                                        \"acc_diff\": user_acc - test_acc,\n",
    "                                        \"acc_diff_adjusted\": user_acc + margin - test_acc,\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "                                # Run non-inferiority test on features directly\n",
    "                                if (\n",
    "                                    len(feature_subset) == 1\n",
    "                                    and margin == 0\n",
    "                                    and classifier == \"logistic_regression\"\n",
    "                                    and (j == 0 or (i == 0 and j == 1))\n",
    "                                ):\n",
    "                                    test_feature_subset = test_features[:, feature_subset].flatten()\n",
    "                                    user_feature_subset = user_features[:, feature_subset].flatten()\n",
    "                                    test_1 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=True,\n",
    "                                    )\n",
    "                                    test_2 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=False,\n",
    "                                    )\n",
    "                                    direct_testing_results.append(\n",
    "                                        {\n",
    "                                            \"data_name\": data_name,\n",
    "                                            \"algorithm\": algorithm,\n",
    "                                            \"seed\": seed,\n",
    "                                            \"model_type\": model_type,\n",
    "                                            \"test_fold\": j,\n",
    "                                            \"test_size\": test_size,\n",
    "                                            \"test_acc\": test_acc,\n",
    "                                            \"user_split\": user_split_name,\n",
    "                                            \"user_filter\": user_filter,\n",
    "                                            \"user_size\": user_size,\n",
    "                                            \"user_acc\": user_acc,\n",
    "                                            \"p_value_increase_good\": test_1[\"p_value\"],\n",
    "                                            \"p_value_decrease_good\": test_2[\"p_value\"],\n",
    "                                            \"ground_truth\": ground_truth,\n",
    "                                            \"feature_subset\": feature_subset,\n",
    "                                            \"acc_diff\": user_acc - test_acc,\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "\n",
    "    # Save results\n",
    "    sf_evals = pd.DataFrame(sf_results)\n",
    "    sf_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/irm/fmow_sf_results_id_subsets_{algorithm}_{model_type}_{seed}_NEW.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    direct_testing_evals = pd.DataFrame(direct_testing_results)\n",
    "    direct_testing_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/irm/fmow_direct_testing_results_id_subsets_{algorithm}_{model_type}_{seed}_NEW.csv\",\n",
    "        index=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD SPLIT SUBSET EVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                         | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2013]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                             | 1/30 [01:36<46:30, 96.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2014]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                          | 2/30 [03:14<45:31, 97.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2015]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                       | 3/30 [04:56<44:49, 99.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▉                                                                                    | 4/30 [06:33<42:41, 98.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▏                                                                                | 5/30 [08:13<41:19, 99.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Africa']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                             | 6/30 [09:46<38:49, 97.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████▋                                                                          | 7/30 [11:26<37:29, 97.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Oceania']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▊                                                                       | 8/30 [12:59<35:20, 96.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████                                                                    | 9/30 [14:34<33:33, 95.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████                                                                | 10/30 [16:09<31:52, 95.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████▏                                                            | 11/30 [17:45<30:22, 95.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▍                                                         | 12/30 [19:19<28:33, 95.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████▌                                                      | 13/30 [20:54<26:55, 95.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▊                                                   | 14/30 [22:28<25:18, 94.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████                                                | 15/30 [24:02<23:37, 94.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████████████▏                                            | 16/30 [25:37<22:06, 94.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████▍                                         | 17/30 [27:13<20:36, 95.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████▌                                      | 18/30 [29:01<19:47, 98.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████████████████▊                                   | 19/30 [30:40<18:07, 98.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████                                | 20/30 [32:17<16:25, 98.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████▏                            | 21/30 [33:56<14:46, 98.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Africa'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████▍                         | 22/30 [35:31<13:00, 97.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████▌                      | 23/30 [37:12<11:29, 98.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Oceania'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████▊                   | 24/30 [38:46<09:42, 97.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████                | 25/30 [40:24<08:06, 97.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████████████▏            | 26/30 [41:57<06:25, 96.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████▍         | 27/30 [43:34<04:49, 96.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████▌      | 28/30 [45:09<03:11, 95.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████▊   | 29/30 [46:47<01:36, 96.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [48:22<00:00, 96.76s/it]\n",
      "  0%|                                                                                                         | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2013]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                             | 1/30 [01:38<47:35, 98.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2014]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                          | 2/30 [03:17<46:07, 98.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2015]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                      | 3/30 [04:59<45:11, 100.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▉                                                                                    | 4/30 [06:37<42:57, 99.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▏                                                                                | 5/30 [08:17<41:28, 99.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Africa']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                             | 6/30 [09:51<39:02, 97.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████▋                                                                          | 7/30 [11:30<37:37, 98.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Oceania']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▊                                                                       | 8/30 [13:04<35:29, 96.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████                                                                    | 9/30 [14:39<33:39, 96.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████                                                                | 10/30 [16:14<31:58, 95.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████▏                                                            | 11/30 [17:51<30:28, 96.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▍                                                         | 12/30 [19:24<28:34, 95.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████▌                                                      | 13/30 [20:59<26:55, 95.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▊                                                   | 14/30 [22:33<25:18, 94.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████                                                | 15/30 [24:08<23:41, 94.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████████████▏                                            | 16/30 [25:42<22:05, 94.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████▍                                         | 17/30 [27:18<20:34, 95.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████▌                                      | 18/30 [29:05<19:45, 98.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████████████████▊                                   | 19/30 [30:44<18:06, 98.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████                                | 20/30 [32:22<16:25, 98.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████▏                            | 21/30 [34:01<14:47, 98.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Africa'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████▍                         | 22/30 [35:36<13:00, 97.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████▌                      | 23/30 [37:16<11:28, 98.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Oceania'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████▊                   | 24/30 [38:50<09:41, 96.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████                | 25/30 [40:27<08:05, 97.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████████████▏            | 26/30 [42:01<06:24, 96.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████▍         | 27/30 [43:38<04:48, 96.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████▌      | 28/30 [45:13<03:11, 95.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████▊   | 29/30 [46:51<01:36, 96.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [48:26<00:00, 96.90s/it]\n",
      "  0%|                                                                                             | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2013]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                  | 1/30 [01:37<47:03, 97.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2014]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▋                                                                               | 2/30 [03:16<46:01, 98.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'year': [2015]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 3/30 [04:59<45:15, 100.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Asia']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▎                                                                         | 4/30 [06:36<43:00, 99.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Europe']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▏                                                                      | 5/30 [08:17<41:32, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Africa']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                    | 6/30 [09:51<39:06, 97.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Americas']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▊                                                                 | 7/30 [11:31<37:42, 98.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': ['Oceania']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▋                                                              | 8/30 [13:04<35:31, 96.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                           | 9/30 [14:39<33:39, 96.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 10/30 [16:15<32:00, 96.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Europe', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▊                                                     | 11/30 [17:51<30:25, 96.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 12/30 [19:25<28:37, 95.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████▍                                               | 13/30 [20:59<26:57, 95.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Asia', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████████▏                                            | 14/30 [22:34<25:22, 95.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 15/30 [24:08<23:42, 94.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2014}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████████▊                                       | 16/30 [25:43<22:07, 94.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: val with filter {'region': 'Americas', 'year': 2015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████▌                                    | 17/30 [27:20<20:40, 95.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 18/30 [29:07<19:47, 98.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████▏                              | 19/30 [30:47<18:09, 99.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████                            | 20/30 [32:24<16:26, 98.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████▊                         | 21/30 [34:03<14:47, 98.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Africa'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████████████████████████████████████▌                      | 22/30 [35:39<13:02, 97.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████▍                   | 23/30 [37:19<11:30, 98.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Oceania'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 24/30 [38:53<09:42, 97.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████              | 25/30 [40:30<08:06, 97.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Europe', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████████████▊           | 26/30 [42:05<06:25, 96.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 27/30 [43:41<04:48, 96.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Asia', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████▍     | 28/30 [45:16<03:11, 95.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████████▏  | 29/30 [46:55<01:36, 96.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating user split: test with filter {'region': 'Americas', 'year': 2017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 30/30 [48:30<00:00, 97.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from suitability.filter.suitability_efficient import SuitabilityFilter\n",
    "from suitability.filter.tests import non_inferiority_ttest\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(32)\n",
    "np.random.seed(32)\n",
    "\n",
    "# Configuration\n",
    "data_name = \"fmow\"\n",
    "root_dir = \"/mfsnic/projects/suitability/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "algorithm = \"ERM\"\n",
    "model_type = \"last\"\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "for seed in seeds:\n",
    "    # Load the features\n",
    "    feature_cache_file = (\n",
    "        f\"suitability/results/features/{data_name}_{algorithm}_{model_type}_{seed}.pkl\"\n",
    "    )\n",
    "    with open(feature_cache_file, \"rb\") as f:\n",
    "        full_feature_dict = pickle.load(f)\n",
    "\n",
    "    # Load the split indices\n",
    "    split_cache_file = f\"suitability/results/split_indices/{data_name}_ood.pkl\"\n",
    "    with open(split_cache_file, \"rb\") as f:\n",
    "        ood_split_dict = pickle.load(f)\n",
    "\n",
    "    # Define suitability filter and experiment parameters\n",
    "    classifiers = [\n",
    "        \"logistic_regression\"\n",
    "    ]  # \"logistic_regression\", \"svm\", \"random_forest\", \"gradient_boosting\", \"mlp\", \"decision_tree\"]\n",
    "    margins = [0, 0.005, 0.01, 0.05]\n",
    "    normalize = True\n",
    "    calibrated = True\n",
    "    sf_results = []\n",
    "    direct_testing_results = []\n",
    "    feature_subsets = [\n",
    "        [0],\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [5],\n",
    "        [6],\n",
    "        [7],\n",
    "        [8],\n",
    "        [9],\n",
    "        [10],\n",
    "        [11],\n",
    "        # [4, 11],\n",
    "        # [4, 11, 8],\n",
    "        # [4, 11, 8, 6],\n",
    "        # [4, 11, 8, 6, 2],\n",
    "        # [4, 11, 8, 6, 2, 1],\n",
    "        # [4, 11, 8, 6, 2, 1, 0],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10],\n",
    "        # [4, 11, 8, 6, 2, 1, 0, 7, 3, 10, 5],\n",
    "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    ]\n",
    "    num_fold_arr = [15]\n",
    "\n",
    "    id_features_val, id_corr_val = full_feature_dict[\"id_val\"]\n",
    "    id_features_test, id_corr_test = full_feature_dict[\"id_test\"]\n",
    "    source_features = np.concatenate([id_features_val, id_features_test], axis=0)\n",
    "    source_corr = np.concatenate([id_corr_val, id_corr_test], axis=0)\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    for user_split_name, user_filter in tqdm(ood_split_dict.keys()):\n",
    "        print(f\"Evaluating user split: {user_split_name} with filter {user_filter}\")\n",
    "\n",
    "        # Get user split indices\n",
    "        user_split_indices = ood_split_dict[(user_split_name, user_filter)]\n",
    "\n",
    "        # Get user split features and correctness\n",
    "        all_features, all_corr = full_feature_dict[user_split_name]\n",
    "        user_features = all_features[user_split_indices]\n",
    "        user_corr = all_corr[user_split_indices]\n",
    "        user_size = len(user_corr)\n",
    "        user_acc = np.mean(user_corr)\n",
    "\n",
    "        for num_folds in num_fold_arr:\n",
    "            source_fold_size = len(source_corr) // num_folds\n",
    "            indices = np.arange(len(source_corr))\n",
    "            np.random.shuffle(indices)\n",
    "            fold_indices = [\n",
    "                indices[i * source_fold_size : (i + 1) * source_fold_size]\n",
    "                for i in range(num_folds)\n",
    "            ]\n",
    "\n",
    "            for i, reg_indices in enumerate(fold_indices):\n",
    "                reg_features = source_features[reg_indices]\n",
    "                reg_corr = source_corr[reg_indices]\n",
    "                reg_size = len(reg_corr)\n",
    "                reg_acc = np.mean(reg_corr)\n",
    "\n",
    "                for j, test_indices in enumerate(fold_indices):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    test_features = source_features[test_indices]\n",
    "                    test_corr = source_corr[test_indices]\n",
    "                    test_size = len(test_corr)\n",
    "                    test_acc = np.mean(test_corr)\n",
    "\n",
    "                    for classifier in classifiers:\n",
    "                        for feature_subset in feature_subsets:\n",
    "                            suitability_filter = SuitabilityFilter(\n",
    "                                test_features,\n",
    "                                test_corr,\n",
    "                                reg_features,\n",
    "                                reg_corr,\n",
    "                                device,\n",
    "                                normalize=normalize,\n",
    "                                feature_subset=feature_subset,\n",
    "                            )\n",
    "                            suitability_filter.train_classifier(\n",
    "                                calibrated=calibrated, classifier=classifier\n",
    "                            )\n",
    "\n",
    "                            for margin in margins:\n",
    "                                # Test suitability filter\n",
    "                                sf_test = suitability_filter.suitability_test(\n",
    "                                    user_features=user_features, margin=margin\n",
    "                                )\n",
    "                                p_value = sf_test[\"p_value\"]\n",
    "                                ground_truth = user_acc >= test_acc - margin\n",
    "\n",
    "                                sf_results.append(\n",
    "                                    {\n",
    "                                        \"data_name\": data_name,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"seed\": seed,\n",
    "                                        \"model_type\": model_type,\n",
    "                                        \"normalize\": normalize,\n",
    "                                        \"calibrated\": calibrated,\n",
    "                                        \"margin\": margin,\n",
    "                                        \"reg_fold\": i,\n",
    "                                        \"reg_size\": reg_size,\n",
    "                                        \"reg_acc\": reg_acc,\n",
    "                                        \"test_fold\": j,\n",
    "                                        \"test_size\": test_size,\n",
    "                                        \"test_acc\": test_acc,\n",
    "                                        \"user_split\": user_split_name,\n",
    "                                        \"user_filter\": user_filter,\n",
    "                                        \"user_size\": user_size,\n",
    "                                        \"user_acc\": user_acc,\n",
    "                                        \"p_value\": p_value,\n",
    "                                        \"ground_truth\": ground_truth,\n",
    "                                        \"classifier\": classifier,\n",
    "                                        \"feature_subset\": feature_subset,\n",
    "                                        \"acc_diff\": user_acc - test_acc,\n",
    "                                        \"acc_diff_adjusted\": user_acc + margin - test_acc,\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "                                # Run non-inferiority test on features directly\n",
    "                                if (\n",
    "                                    len(feature_subset) == 1\n",
    "                                    and margin == 0\n",
    "                                    and classifier == \"logistic_regression\"\n",
    "                                    and (j == 0 or (i == 0 and j == 1))\n",
    "                                ):\n",
    "                                    test_feature_subset = test_features[:, feature_subset].flatten()\n",
    "                                    user_feature_subset = user_features[:, feature_subset].flatten()\n",
    "                                    test_1 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=True,\n",
    "                                    )\n",
    "                                    test_2 = non_inferiority_ttest(\n",
    "                                        test_feature_subset,\n",
    "                                        user_feature_subset,\n",
    "                                        increase_good=False,\n",
    "                                    )\n",
    "                                    direct_testing_results.append(\n",
    "                                        {\n",
    "                                            \"data_name\": data_name,\n",
    "                                            \"algorithm\": algorithm,\n",
    "                                            \"seed\": seed,\n",
    "                                            \"model_type\": model_type,\n",
    "                                            \"test_fold\": j,\n",
    "                                            \"test_size\": test_size,\n",
    "                                            \"test_acc\": test_acc,\n",
    "                                            \"user_split\": user_split_name,\n",
    "                                            \"user_filter\": user_filter,\n",
    "                                            \"user_size\": user_size,\n",
    "                                            \"user_acc\": user_acc,\n",
    "                                            \"p_value_increase_good\": test_1[\"p_value\"],\n",
    "                                            \"p_value_decrease_good\": test_2[\"p_value\"],\n",
    "                                            \"ground_truth\": ground_truth,\n",
    "                                            \"feature_subset\": feature_subset,\n",
    "                                            \"acc_diff\": user_acc - test_acc,\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "    # Save results\n",
    "    sf_evals = pd.DataFrame(sf_results)\n",
    "    sf_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/erm/fmow_sf_results_ood_subsets_{algorithm}_{model_type}_{seed}_NEW.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    direct_testing_evals = pd.DataFrame(direct_testing_results)\n",
    "    direct_testing_evals.to_csv(\n",
    "        f\"suitability/results/sf_evals/erm/fmow_direct_testing_results_ood_subsets_{algorithm}_{model_type}_{seed}_NEW.csv\",\n",
    "        index=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
