{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring WILDS datasets and models\n",
    "### FMoW\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "import wilds\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from examples.utils import load\n",
    "from examples.models.initializer import initialize_torchvision_model, initialize_bert_based_model\n",
    "from examples.transforms import initialize_transform\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset=\"civilcomments\", download=False, root_dir=\"/mfsnic/u/apouget/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and evaluate trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the following work, a small change is needed in the `wilds` package code. In `<conda_env>/lib/python3.11/site-packages/wilds/datasets/fmow_dataset.py`, add the `format='ISO8601'` argument to each `pd.to_datetime()` function call (3 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_from_state_dict(state_dict, prefix='model.'):\n",
    "    \"\"\"\n",
    "    Remove the prefix from the keys in state_dict if it exists.\n",
    "    \"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_state_dict[k[len(prefix):]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertClassifier were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.09310669596806\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"civilcomments\"\n",
    "dataset = get_dataset(dataset=dataset_name, download=False, root_dir=\"/mfsnic/u/apouget/data/\")\n",
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "\n",
    "if dataset_name == \"iwildcam\":\n",
    "    config.target_resolution = (448, 448)\n",
    "elif dataset_name == \"fmow\":\n",
    "    config.target_resolution = (224, 224)\n",
    "elif dataset_name == \"civilcomments\":\n",
    "    config.model = \"distilbert-base-uncased\"\n",
    "    config.max_token_length = 300\n",
    "    config.pretrained_model_path = None\n",
    "    config.model_kwargs = {}\n",
    "\n",
    "if dataset_name == \"iwildcam\" or dataset_name == \"fmow\":\n",
    "    eval_transform = initialize_transform(\n",
    "        transform_name=\"image_base\",\n",
    "        config=config,\n",
    "        dataset=dataset,\n",
    "        is_training=False)\n",
    "elif dataset_name == \"civilcomments\":\n",
    "    eval_transform = initialize_transform(\n",
    "        transform_name=\"bert\",\n",
    "        config=config,\n",
    "        dataset=dataset,\n",
    "        is_training=False)\n",
    "\n",
    "# Get the test set\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\",\n",
    "    transform=eval_transform,\n",
    ")\n",
    "\n",
    "# Prepare the data loader\n",
    "test_loader = get_eval_loader(\"standard\", test_data, batch_size=16, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dataset_name == \"iwildcam\":\n",
    "    model = initialize_torchvision_model(\"resnet50\", d_out=dataset.n_classes, pretrained=True)\n",
    "elif dataset_name == \"fmow\":\n",
    "    model = initialize_torchvision_model(\"densenet121\", d_out=dataset.n_classes, pretrained=True)\n",
    "elif dataset_name == \"civilcomments\":\n",
    "    model = initialize_bert_based_model(config, d_out=dataset.n_classes)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset {dataset_name}\")\n",
    "state_dict = remove_prefix_from_state_dict(torch.load(f\"/mfsnic/u/apouget/experiments/{dataset_name}/{dataset_name}_seed:0_epoch:last_model.pth\")['algorithm'])\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_accuracy_and_confidence(model, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confidence_scores = []\n",
    "    correctness = np.array([])\n",
    "    label_arr = np.array([])\n",
    "    pred_arr = np.array([])\n",
    "    meta_arr = np.array([])\n",
    "    \n",
    "    with torch.no_grad():  # No need to calculate gradients for evaluation\n",
    "        for data in dataloader:\n",
    "            images, labels, meta = data\n",
    "            # Meta explanation\n",
    "            # For fmow we have [region, year, labels, ?], region: {0: Asia, 1: Europe, 2: Africa, 3: Americas, 4: Oceania}, year: {14: 2016, 15: 2017}\n",
    "            # For iwildcam we have [id], camera trap location id\n",
    "            # For civilcomments we have [male, female, LGBTQ, christian, muslim, other_religions, black, white, identity_any, severe_toxicity, obscene, threat, insult, identity_attack, sexual_explicit, y, ?]\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get the predicted class by taking the argmax of the output tensor\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            softmax_scores = F.softmax(outputs, dim=1)\n",
    "            max_confidences, _ = torch.max(softmax_scores, dim=1)\n",
    "            confidence_scores.extend(max_confidences.cpu().numpy())\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            correctness = np.append(correctness, (predicted == labels).cpu().numpy())\n",
    "            label_arr = np.append(label_arr, labels.cpu().numpy())\n",
    "            pred_arr = np.append(pred_arr, predicted.cpu().numpy())\n",
    "            meta_arr = np.append(meta_arr, meta.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total * 100\n",
    "    return accuracy, confidence_scores, np.array(correctness, dtype=bool), label_arr, pred_arr, meta_arr\n",
    "\n",
    "# Evaluate\n",
    "acc, conf, correct, labels, preds, meta = get_accuracy_and_confidence(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'acc_avg': 0.9209310412406921,\n",
       "  'acc_y:0_male:1': 0.9365696310997009,\n",
       "  'count_y:0_male:1': 12092.0,\n",
       "  'acc_y:1_male:1': 0.6291421055793762,\n",
       "  'count_y:1_male:1': 2203.0,\n",
       "  'acc_y:0_female:1': 0.9459764361381531,\n",
       "  'count_y:0_female:1': 14179.0,\n",
       "  'acc_y:1_female:1': 0.608810544013977,\n",
       "  'count_y:1_female:1': 2270.0,\n",
       "  'acc_y:0_LGBTQ:1': 0.8732087016105652,\n",
       "  'count_y:0_LGBTQ:1': 3210.0,\n",
       "  'acc_y:1_LGBTQ:1': 0.5929276347160339,\n",
       "  'count_y:1_LGBTQ:1': 1216.0,\n",
       "  'acc_y:0_christian:1': 0.9611602425575256,\n",
       "  'count_y:0_christian:1': 12101.0,\n",
       "  'acc_y:1_christian:1': 0.5396825671195984,\n",
       "  'count_y:1_christian:1': 1260.0,\n",
       "  'acc_y:0_muslim:1': 0.9055088758468628,\n",
       "  'count_y:0_muslim:1': 5355.0,\n",
       "  'acc_y:1_muslim:1': 0.5697603225708008,\n",
       "  'count_y:1_muslim:1': 1627.0,\n",
       "  'acc_y:0_other_religions:1': 0.9392617344856262,\n",
       "  'count_y:0_other_religions:1': 2980.0,\n",
       "  'acc_y:1_other_religions:1': 0.5634615421295166,\n",
       "  'count_y:1_other_religions:1': 520.0,\n",
       "  'acc_y:0_black:1': 0.8401799201965332,\n",
       "  'count_y:0_black:1': 3335.0,\n",
       "  'acc_y:1_black:1': 0.6519193053245544,\n",
       "  'count_y:1_black:1': 1537.0,\n",
       "  'acc_y:0_white:1': 0.8605626225471497,\n",
       "  'count_y:0_white:1': 5723.0,\n",
       "  'acc_y:1_white:1': 0.6406945586204529,\n",
       "  'count_y:1_white:1': 2246.0,\n",
       "  'acc_wg': 0.5396825671195984},\n",
       " 'Average acc: 0.921\\n  male                   acc on non_toxic: 0.937 (n =  12092)    acc on toxic: 0.629 (n =   2203) \\n  female                 acc on non_toxic: 0.946 (n =  14179)    acc on toxic: 0.609 (n =   2270) \\n  LGBTQ                  acc on non_toxic: 0.873 (n =   3210)    acc on toxic: 0.593 (n =   1216) \\n  christian              acc on non_toxic: 0.961 (n =  12101)    acc on toxic: 0.540 (n =   1260) \\n  muslim                 acc on non_toxic: 0.906 (n =   5355)    acc on toxic: 0.570 (n =   1627) \\n  other_religions        acc on non_toxic: 0.939 (n =   2980)    acc on toxic: 0.563 (n =    520) \\n  black                  acc on non_toxic: 0.840 (n =   3335)    acc on toxic: 0.652 (n =   1537) \\n  white                  acc on non_toxic: 0.861 (n =   5723)    acc on toxic: 0.641 (n =   2246) \\nWorst-group acc: 0.540\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.eval(torch.tensor(preds), torch.tensor(labels), torch.tensor(meta.reshape(133782, 17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
